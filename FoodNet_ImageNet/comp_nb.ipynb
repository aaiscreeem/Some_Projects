{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (0.21.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (0.5.7)\n",
      "Requirement already satisfied: hdbscan in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (0.8.40)\n",
      "Requirement already satisfied: numpy in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from umap-learn) (0.61.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\onedrive\\desktop\\782 a2\\test_env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision scikit-learn umap-learn hdbscan numpy tqdm Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\OneDrive\\Desktop\\782 A2\\test_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading images from: apple_pie (Class 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 233591.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: beef_carpaccio (Class 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 139990.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: beef_tartare (Class 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174908.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: caesar_salad (Class 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174627.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: caprese_salad (Class 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 176136.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: carrot_cake (Class 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 175368.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: cheesecake (Class 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 139950.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: club_sandwich (Class 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 175117.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: creme_brulee (Class 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 236889.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: croque_madame (Class 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 152758.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: cup_cakes (Class 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 70011.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: donuts (Class 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 77779.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: escargots (Class 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 140230.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: hamburger (Class 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174440.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: hot_and_sour_soup (Class 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 173862.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: hummus (Class 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 350652.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: miso_soup (Class 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 233498.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: oysters (Class 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 231565.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: paella (Class 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174960.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: pho (Class 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 175179.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: pork_chop (Class 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174752.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: ramen (Class 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 139990.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: samosa (Class 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174970.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: sashimi (Class 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 140010.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: shrimp_and_grits (Class 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 233461.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: spaghetti_bolognese (Class 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174627.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: strawberry_shortcake (Class 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174991.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: tacos (Class 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 174970.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: takoyaki (Class 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 175263.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: tiramisu (Class 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:00<00:00, 175096.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21000 images across 30 classes.\n",
      "Training samples: 16800, Testing samples: 4200\n",
      "Filtered Training samples: 16800, Filtered Testing samples: 4200\n",
      "Using 4 workers for DataLoaders.\n",
      "Loading pre-trained EfficientNet-B0 model...\n",
      "Unfreezing layers:\n",
      "  - Sequential\n",
      "  - Conv2dNormActivation\n",
      "Total parameters: 4,045,978\n",
      "Trainable parameters: 450,590\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "import umap\n",
    "import hdbscan\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "folders = [\"kaggle_train/food-101/apple_pie\", \"kaggle_train/food-101/beef_carpaccio\", \"kaggle_train/food-101/beef_tartare\", \"kaggle_train/food-101/caesar_salad\", \"kaggle_train/food-101/caprese_salad\", \"kaggle_train/food-101/carrot_cake\", \"kaggle_train/food-101/cheesecake\", \"kaggle_train/food-101/club_sandwich\", \"kaggle_train/food-101/creme_brulee\", \"kaggle_train/food-101/croque_madame\", \"kaggle_train/food-101/cup_cakes\", \"kaggle_train/food-101/donuts\", \"kaggle_train/food-101/escargots\", \"kaggle_train/food-101/hamburger\", \"kaggle_train/food-101/hot_and_sour_soup\", \"kaggle_train/food-101/hummus\", \"kaggle_train/food-101/miso_soup\", \"kaggle_train/food-101/oysters\", \"kaggle_train/food-101/paella\", \"kaggle_train/food-101/pho\", \"kaggle_train/food-101/pork_chop\", \"kaggle_train/food-101/ramen\", \"kaggle_train/food-101/samosa\", \"kaggle_train/food-101/sashimi\", \"kaggle_train/food-101/shrimp_and_grits\", \"kaggle_train/food-101/spaghetti_bolognese\", \"kaggle_train/food-101/strawberry_shortcake\", \"kaggle_train/food-101/tacos\", \"kaggle_train/food-101/takoyaki\", \"kaggle_train/food-101/tiramisu\"]\n",
    "num_classes = len(folders)\n",
    "img_size = 224 # EfficientNet-B0 input size\n",
    "batch_size = 16 # Adjust based on your CPU RAM. Lower if you run out of memory.\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10   # *** CRITICAL: Fine-tuning on CPU is VERY SLOW. Start with few epochs (1-3). ***\n",
    "test_split_ratio = 0.2\n",
    "random_state = 782 # for reproducibility\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cpu':\n",
    "    warnings.warn(\"GPU not available, running on CPU. Fine-tuning and prediction will be slower.\")\n",
    "\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "\n",
    "def get_image_paths_and_labels(folder_list):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    label_map = {folder_path: i for i, folder_path in enumerate(folder_list)}\n",
    "    for i, folder_path in enumerate(folder_list):\n",
    "        if not os.path.isdir(folder_path):\n",
    "             warnings.warn(f\"Folder not found: {folder_path}. Skipping.\")\n",
    "             continue\n",
    "        print(f\"Loading images from: {os.path.basename(folder_path)} (Class {i})\")\n",
    "        try:\n",
    "            for filename in tqdm(os.listdir(folder_path)):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    image_paths.append(os.path.join(folder_path, filename))\n",
    "                    labels.append(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading folder {folder_path}: {e}\")\n",
    "    print(f\"Found {len(image_paths)} images across {len(set(labels))} classes.\")\n",
    "    return image_paths, labels, label_map\n",
    "\n",
    "all_image_paths, all_labels, label_map = get_image_paths_and_labels(folders)\n",
    "\n",
    "if not all_image_paths:\n",
    "    raise ValueError(\"No images found. Please check your 'folders' paths.\")\n",
    "\n",
    "# Split data\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    all_image_paths,\n",
    "    all_labels,\n",
    "    test_size=test_split_ratio,\n",
    "    random_state=random_state,\n",
    "    stratify=all_labels # Ensure proportional representation of classes\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_paths)}, Testing samples: {len(test_paths)}\")\n",
    "\n",
    "# Define transformations\n",
    "# EfficientNet expects specific normalization\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256), # Resize slightly larger first\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Custom Dataset\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            # Ensure image is loaded in RGB format\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error loading image {img_path}: {e}. Returning dummy data.\")\n",
    "            # Return dummy data of the correct shape to avoid crashing the DataLoader\n",
    "            image = torch.zeros((3, img_size, img_size))\n",
    "            label = -1 # Indicate an error\n",
    "        return image, label\n",
    "\n",
    "train_dataset = FoodDataset(train_paths, train_labels, transform=train_transform)\n",
    "test_dataset = FoodDataset(test_paths, test_labels, transform=test_transform)\n",
    "\n",
    "# Filter out potential dummy data introduced by loading errors before creating DataLoader\n",
    "train_dataset.image_paths = [p for i, p in enumerate(train_dataset.image_paths) if train_dataset.labels[i] != -1]\n",
    "train_dataset.labels = [l for l in train_dataset.labels if l != -1]\n",
    "test_dataset.image_paths = [p for i, p in enumerate(test_dataset.image_paths) if test_dataset.labels[i] != -1]\n",
    "test_dataset.labels = [l for l in test_dataset.labels if l != -1]\n",
    "# Need to update the actual test_labels list used later for evaluation\n",
    "test_labels = test_dataset.labels # Update test_labels after filtering\n",
    "\n",
    "print(f\"Filtered Training samples: {len(train_dataset)}, Filtered Testing samples: {len(test_dataset)}\")\n",
    "\n",
    "num_workers = 4 if device.type == 'cuda' else 0\n",
    "print(f\"Using {num_workers} workers for DataLoaders.\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# --- 2. Model Selection and Modification ---\n",
    "\n",
    "print(\"Loading pre-trained EfficientNet-B0 model...\")\n",
    "# Choose EfficientNet-B0: Smallest version, best for CPU\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "# Freeze all parameters initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Identify parameters to unfreeze (last layers)\n",
    "# Unfreeze the final classifier layer and the last convolutional block (features[-1])\n",
    "num_ftrs = model.classifier[1].in_features # Get input features of the original classifier\n",
    "layers_to_unfreeze = [model.classifier]\n",
    "if hasattr(model, 'features') and len(model.features) > 0:\n",
    "     layers_to_unfreeze.append(model.features[-1]) # Unfreeze last feature block\n",
    "\n",
    "print(\"Unfreezing layers:\")\n",
    "for layer in layers_to_unfreeze:\n",
    "     print(f\"  - {layer.__class__.__name__}\")\n",
    "     for param in layer.parameters():\n",
    "          param.requires_grad = True\n",
    "\n",
    "# Replace the final classifier layer for our 30 classes\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True), # Standard dropout for EfficientNet\n",
    "    nn.Linear(num_ftrs, num_classes)\n",
    ")\n",
    "# Ensure the *new* classifier parameters require gradients\n",
    "for param in model.classifier.parameters():\n",
    "     param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on: cuda:0\n",
      "\n",
      "Starting fine-tuning for 10 epochs on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/1050 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Fine-tuning ---\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "print(f\"Model on: {next(model.parameters()).device}\")  # Should print 'cuda'\n",
    "\n",
    "# Filter parameters for the optimizer to only include those that require gradients\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "print(f\"\\nStarting fine-tuning for {num_epochs} epochs on {device}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Skip batches with errors (label == -1)\n",
    "        valid_indices = labels != -1\n",
    "        if not torch.any(valid_indices):\n",
    "            continue\n",
    "        inputs = inputs[valid_indices]\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):  # Enables mixed precision\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Fine-tuning finished in {(end_time - start_time)/60:.2f} minutes.\")\n",
    "\n",
    "# --- 4. Feature Extraction ---\n",
    "\n",
    "print(\"\\nExtracting features from the fine-tuned model using test data...\")\n",
    "\n",
    "# We want features before the final classification layer.\n",
    "# Modify the model to output features from the layer before the classifier.\n",
    "# This is typically the output of the AdaptiveAvgPool layer in EfficientNet.\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-1]) # Select all layers except the last one (classifier)\n",
    "feature_extractor.to(device)\n",
    "feature_extractor.eval() # Set to evaluation mode\n",
    "\n",
    "all_features = []\n",
    "all_test_labels = [] # Store labels corresponding to extracted features\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Extracting Features\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Skip batches with errors (label == -1)\n",
    "        valid_indices = labels != -1\n",
    "        if not torch.any(valid_indices):\n",
    "            continue\n",
    "        inputs = inputs[valid_indices]\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "        features = feature_extractor(inputs)\n",
    "        # The output of avgpool might need flattening\n",
    "        features = torch.flatten(features, 1)\n",
    "        all_features.append(features.cpu().numpy())\n",
    "        all_test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate features and labels from all batches\n",
    "features_np = np.concatenate(all_features, axis=0)\n",
    "# Make sure the labels used here correspond exactly to the extracted features\n",
    "true_labels_np = np.concatenate(all_test_labels, axis=0)\n",
    "\n",
    "print(f\"Extracted features shape: {features_np.shape}\")\n",
    "print(f\"Corresponding true labels shape: {true_labels_np.shape}\")\n",
    "# Check if shapes match the filtered test dataset size\n",
    "if features_np.shape[0] != len(test_dataset):\n",
    "     warnings.warn(f\"Mismatch in feature count ({features_np.shape[0]}) and filtered test set size ({len(test_dataset)}). Check for batch drop issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming classification prediction on test data...\")\n",
    "model.eval() # Set model to evaluation mode\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculations for inference\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        # ***** Move data to GPU *****\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # ***************************\n",
    "\n",
    "        # Skip batches with errors (label == -1)\n",
    "        valid_indices = labels != -1\n",
    "        if not torch.any(valid_indices):\n",
    "            continue\n",
    "        inputs = inputs[valid_indices]\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Move predictions and labels back to CPU for collection\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_true.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate all predictions and true labels\n",
    "predictions_np = np.concatenate(all_preds)\n",
    "true_labels_np = np.concatenate(all_true) # Use the labels collected directly from the test loader loop\n",
    "\n",
    "# Ensure the collected true labels match the filtered dataset labels length\n",
    "if len(true_labels_np) != len(test_labels):\n",
    "     warnings.warn(f\"Mismatch in collected true labels ({len(true_labels_np)}) and filtered test set size ({len(test_labels)}). Check data loading/filtering.\")\n",
    "     # If a mismatch occurs, using actual_test_labels_list might be safer if prediction loop didn't skip batches\n",
    "     if len(predictions_np) == len(test_labels):\n",
    "         print(\"Adjusting true labels to match filtered test set size for F1 score.\")\n",
    "         true_labels_np = np.array(test_labels)\n",
    "     else:\n",
    "         raise ValueError(\"Cannot resolve label mismatch for F1 score calculation.\")\n",
    "\n",
    "\n",
    "# Calculate F1 score\n",
    "# 'weighted' averages the F1 score for each class, weighted by support (number of true instances per class)\n",
    "# This is generally recommended for multi-class classification, especially with potential imbalance.\n",
    "f1_weighted = f1_score(true_labels_np, predictions_np, average='weighted')\n",
    "f1_macro = f1_score(true_labels_np, predictions_np, average='macro') # Unweighted average\n",
    "\n",
    "print(\"\\n--- Classification Results ---\")\n",
    "print(f\"Weighted F1 Score on Test Set: {f1_weighted:.4f}\")\n",
    "print(f\"Macro F1 Score on Test Set: {f1_macro:.4f}\") # Macro gives equal weight to each class\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
